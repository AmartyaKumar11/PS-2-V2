# Resume Classification ML Pipeline

A comprehensive machine learning pipeline for automated resume classification using both supervised and unsupervised approaches. This project creates labels from semantic similarity scores and evaluates multiple algorithms to classify resumes as fit/unfit for job positions.

## ğŸš€ Features

- **Automated Resume Parsing**: Extract and clean text from various resume formats
- **Semantic Similarity Analysis**: Uses Sentence-BERT for job-resume matching
- **Multiple ML Approaches**: 6 supervised + 5 unsupervised algorithms
- **Label Creation Strategies**: Binary, percentile-based, and conservative labeling
- **Feature Engineering**: TF-IDF and Count Vectorization with optimization
- **Model Validation**: Cross-validation, correlation analysis, and business logic validation
- **Comprehensive Documentation**: Well-documented Jupyter notebooks with explanations

## ğŸ“ Project Structure

```
PS-2/
â”œâ”€â”€ README.md                           # Main project documentation
â”œâ”€â”€ requirements.txt                    # Python dependencies
â”œâ”€â”€ .gitignore                         # Git ignore file
â”œâ”€â”€ LICENSE                            # Project license
â”‚
â”œâ”€â”€ notebooks/                         # Jupyter notebooks
â”‚   â”œâ”€â”€ resume_preprocessing.ipynb     # Data cleaning and preprocessing
â”‚   â””â”€â”€ resume_classification_ml.ipynb # ML pipeline and analysis
â”‚
â”œâ”€â”€ src/                              # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ data_preprocessing.py         # Data preprocessing utilities
â”‚   â”œâ”€â”€ feature_engineering.py       # Feature extraction functions
â”‚   â”œâ”€â”€ model_training.py            # ML model training
â”‚   â””â”€â”€ evaluation.py                # Model evaluation utilities
â”‚
â”œâ”€â”€ data/                             # Data files
â”‚   â”œâ”€â”€ raw/                         # Raw resume files
â”‚   â”œâ”€â”€ processed/                   # Processed datasets
â”‚   â”‚   â”œâ”€â”€ parsed_resumes.csv
â”‚   â”‚   â”œâ”€â”€ preprocessed_resumes.csv
â”‚   â”‚   â”œâ”€â”€ preprocessed_resumes_lemmatized.csv
â”‚   â”‚   â””â”€â”€ resume_matching_results_final.csv
â”‚   â”œâ”€â”€ results/                     # Model outputs
â”‚   â”‚   â”œâ”€â”€ ml_model_comparison_results.csv
â”‚   â”‚   â”œâ”€â”€ final_ml_predictions.csv
â”‚   â”‚   â””â”€â”€ feature_importance_analysis.csv
â”‚   â””â”€â”€ job_descriptions/            # Job description files
â”‚       â””â”€â”€ Web-Developer-job-description.txt
â”‚
â”œâ”€â”€ models/                          # Trained models
â”‚   â”œâ”€â”€ trained_models/
â”‚   â”‚   â”œâ”€â”€ logistic_regression_binary/
â”‚   â”‚   â”œâ”€â”€ random_forest_multiclass/
â”‚   â”‚   â””â”€â”€ README.md
â”‚   â””â”€â”€ model_configs/               # Model configurations
â”‚
â”œâ”€â”€ scripts/                         # Utility scripts
â”‚   â”œâ”€â”€ parse_resumes_script.py      # Resume parsing script
â”‚   â”œâ”€â”€ cleanup_project.py           # Project cleanup utility
â”‚   â””â”€â”€ run_pipeline.py              # Complete pipeline runner
â”‚
â”œâ”€â”€ docs/                            # Documentation
â”‚   â”œâ”€â”€ PROJECT_SUMMARY.md           # Detailed project summary
â”‚   â”œâ”€â”€ API_DOCUMENTATION.md         # API documentation
â”‚   â”œâ”€â”€ DEPLOYMENT_GUIDE.md          # Deployment instructions
â”‚   â””â”€â”€ METHODOLOGY.md               # Technical methodology
â”‚
â””â”€â”€ tests/                           # Unit tests
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ test_preprocessing.py
    â”œâ”€â”€ test_feature_engineering.py
    â””â”€â”€ test_models.py
```

## ğŸ› ï¸ Installation

### Prerequisites
- Python 3.8+
- pip or conda package manager

### Setup
1. Clone the repository:
```bash
git clone https://github.com/yourusername/resume-classification-ml.git
cd resume-classification-ml
```

2. Create a virtual environment:
```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

3. Install dependencies:
```bash
pip install -r requirements.txt
```

## ğŸš€ Quick Start

### 1. Data Preprocessing
```bash
jupyter notebook notebooks/resume_preprocessing.ipynb
```

### 2. ML Pipeline
```bash
jupyter notebook notebooks/resume_classification_ml.ipynb
```

### 3. Complete Pipeline (Script)
```bash
python scripts/run_pipeline.py --input data/raw --output data/results
```

## ğŸ“Š Results Summary

### Model Performance
- **Best Supervised Model**: Logistic Regression (F1: 0.72, Accuracy: 69%)
- **Best Unsupervised Model**: K-Means (Silhouette Score: 0.45)
- **Correlation with Similarity Scores**: 0.68 (Pearson correlation)

### Key Findings
- Technical skills are the strongest predictors
- Experience keywords significantly impact classification
- Conservative labeling improves model reliability
- Ensemble methods show promise for production use

## ğŸ”§ Configuration

### Model Parameters
Models are configured with regularization to prevent overfitting:
- **Logistic Regression**: C=0.1 (strong regularization)
- **Random Forest**: max_depth=10, n_estimators=50
- **XGBoost**: learning_rate=0.1, max_depth=6

### Feature Engineering
- **TF-IDF**: max_features=1000, min_df=2, max_df=0.8
- **N-grams**: (1,2) for unigrams and bigrams
- **Preprocessing**: Lemmatization, stop word removal

## ğŸ“ˆ Usage Examples

### Basic Classification
```python
from src.model_training import ResumeClassifier

classifier = ResumeClassifier()
classifier.load_model('models/best_model.pkl')
prediction = classifier.predict(resume_text)
```

### Batch Processing
```python
from src.evaluation import batch_classify

results = batch_classify(
    resume_files='data/raw/*.pdf',
    job_description='data/job_descriptions/Web-Developer.txt',
    output_file='data/results/predictions.csv'
)
```

## ğŸ§ª Testing

Run the test suite:
```bash
python -m pytest tests/ -v
```

## ğŸ“– Documentation

- **[Project Summary](docs/PROJECT_SUMMARY.md)**: Comprehensive project overview
- **[Methodology](docs/METHODOLOGY.md)**: Technical approach and algorithms
- **[API Documentation](docs/API_DOCUMENTATION.md)**: Function and class references
- **[Deployment Guide](docs/DEPLOYMENT_GUIDE.md)**: Production deployment instructions

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ‘¨â€ğŸ’» Author

**Amartya Kumar**
- Project developed during PS-2 internship
- Focus: Machine Learning, NLP, Resume Classification

## ğŸ™ Acknowledgments

- Sentence-BERT for semantic similarity computation
- scikit-learn for machine learning algorithms
- XGBoost for gradient boosting implementation
- Jupyter for interactive development environment

## ğŸ“ Support

For questions and support:
- Create an issue in this repository
- Check the [documentation](docs/)
- Review the [troubleshooting guide](docs/TROUBLESHOOTING.md)

---

**Note**: This project demonstrates a complete ML pipeline with realistic performance expectations and production-ready code structure.
